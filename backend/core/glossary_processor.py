import pandas as pd
import json
import re
import os
import concurrent.futures
from backend.core.ai_service import AIService
from backend.config_manager import load_config

class GlossaryProcessor:
    def __init__(self, ai_service: AIService):
        self.ai_service = ai_service
        self.config = load_config()

    def load_data(self, glossary_path, reference_path):
        glossary_df = pd.read_excel(glossary_path, engine='openpyxl')
        original_cols = glossary_df.columns.tolist()
        rename_map = {original_cols[0]: 'src', original_cols[1]: 'dst'}
        glossary_df = glossary_df.rename(columns=rename_map)
        
        # Ensure src and dst are strings, but leave other columns (like count) as is
        glossary_df['src'] = glossary_df['src'].fillna('').astype(str)
        glossary_df['dst'] = glossary_df['dst'].fillna('').astype(str)

        with open(reference_path, 'r', encoding='utf-8') as f:
            content = f.read().replace('\r\n', '\n').replace('\r', '\n')
        
        reference_dict = {}
        
        # Strategy 1: Try parsing with "åŸæ–‡ï¼š" markers
        if 'åŸæ–‡ï¼š' in content:
            blocks = content.split('åŸæ–‡ï¼š')[1:]
            for block in blocks:
                match = re.search(r'^(?P<korean_term>.*?)\n.*?(?P<context>.*)', block, re.DOTALL)
                if match:
                    korean_term = match.group('korean_term').strip()
                    ctx = match.group('context').strip().replace("â€»", "")
                    reference_dict[korean_term] = ctx

        # Strategy 2: Fallback to Raw Text Search if Strategy 1 found nothing or very few
        # (Or we can just do this for any missing term later, but pre-building is better for performance if possible)
        # Let's do a hybrid approach: Pre-build if markers exist, otherwise strict search on demand (or pre-build for all terms now)
        
        if not reference_dict:
            # Treat as raw novel text
            # For each term in glossary, find it in content
            lines = content.split('\n')
            for term in glossary_df['src'].unique():
                term = term.strip()
                if not term: continue
                
                # Simple search: find first occurrence of term and extract surrounding lines
                # To be more robust, we could find the line with the term
                found_ctx = []
                for i, line in enumerate(lines):
                    if term in line:
                        # Extract this line and maybe previous/next for context
                        start = max(0, i - 1)
                        end = min(len(lines), i + 2)
                        ctx_block = "\n".join(lines[start:end]).strip()
                        found_ctx.append(ctx_block)
                        if len(found_ctx) >= 1: break # Just take the first meaningful occurrence
                
                if found_ctx:
                    reference_dict[term] = found_ctx[0]
        
        return glossary_df, reference_dict, original_cols

    def process_batch(self, batch_df, novel_background, reference_dict, log_callback=None):
        batch_list = []
        character_keywords = ['è§’è‰²', 'ç¥ç¥‡/ä¼ è¯´äººç‰©', 'ç”·æ€§è§’è‰²', 'å¥³æ€§è§’è‰²']
        for _, row in batch_df.iterrows():
            korean_term = row['src'].strip()
            batch_list.append({
                "korean_term": korean_term,
                "chinese_translation": row['dst'].strip(),
                "is_character": any(keyword in row.get('info', '') for keyword in character_keywords),
                "context": reference_dict.get(korean_term, f"æœªåœ¨å‚è€ƒæ–‡ä»¶ä¸­æ‰¾åˆ°æœ¯è¯­ '{korean_term}' çš„ä¸Šä¸‹æ–‡ã€‚")
            })
        
        prompt = self._get_batch_prompt(novel_background, batch_list)
        response = self.ai_service.call_api(prompt, log_callback=log_callback)
        return self._parse_json_response(response)

    def _get_batch_prompt(self, novel_background, batch_list):
        user_prompt = self.config.get("prompts", {}).get("batch_review", "")
        if not user_prompt:
             # Fallback default if config is empty
             user_prompt = """è§’è‰²ï¼šä¸“ä¸šå°è¯´ç¿»è¯‘å®¶ï¼ˆV3Â·æ‰¹å¤„ç†æ¨¡å¼ï¼‰

èº«ä»½ä¸ä½¿å‘½
ä½ æ˜¯ä¸€ä½é¡¶çº§çš„éŸ©ä¸­ç¿»è¯‘å¤å®¡ä¸“å®¶ã€‚
ä½ çš„ä»»åŠ¡æ˜¯æ¥æ”¶ä¸€æ‰¹æœ¯è¯­ï¼Œå¹¶å¯¹å…¶ä¸­çš„æ¯ä¸€æ¡è¿›è¡Œç‹¬ç«‹ã€ç²¾ç¡®ä¸”åŸºäºä¸Šä¸‹æ–‡çš„ä¸€è‡´æ€§å®¡æŸ¥ã€‚

æ ¸å¿ƒè¡Œä¸ºå‡†åˆ™ï¼ˆå¼ºåŒ–ç‰ˆï¼‰
ç»å¯¹å¿ äºã€Œå°è¯´èƒŒæ™¯è®¾å®šã€ä¸ã€Œæœ¯è¯­æ‰€åœ¨åŸæ–‡å‚è€ƒã€ï¼Œè¿™æ˜¯æ‰€æœ‰åˆ¤æ–­çš„æœ€é«˜ä¾æ®ã€‚
ä¸“æœ‰åè¯ï¼ˆå°¤å…¶æ˜¯äººåï¼‰çš„ä¸€è‡´æ€§ä¼˜å…ˆçº§é«˜äºå­—é¢ç¿»è¯‘å‡†ç¡®æ€§ã€‚
åªè¦è¯¥è¯‘ååœ¨å°è¯´ä¸­å·²å½¢æˆç¨³å®šå¯¹åº”å…³ç³»ï¼Œä¸å¾—å› ç¼©å†™ã€æ˜µç§°æˆ–å½¢æ€å˜åŒ–è€Œéšæ„ä¿®æ”¹ã€‚
å…è®¸å¹¶å¿…é¡»è¯†åˆ«"åŒä¸€è§’è‰²çš„ä¸åŒæŒ‡ä»£å½¢å¼"ï¼ˆå…¨å/çœç•¥å/æ˜µç§°ï¼‰ï¼Œå¹¶ç¡®ä¿å…¶ä¸­æ–‡è¯‘ååœ¨è§„åˆ™ä¸‹ä¿æŒç»Ÿä¸€é€»è¾‘ã€‚
å¯¹æ™®é€šè¯æ±‡ï¼Œæ‰§è¡Œ"ç²¾ç®€åŸåˆ™"ï¼š
åˆ é™¤ä¸å¿…è¦çš„é€šç”¨è¯ã€åŠ¨è¯ã€å½¢å®¹è¯å’Œæè¿°æ€§çŸ­è¯­ï¼Œä»…ä¿ç•™å…·å¤‡æœ¯è¯­ä»·å€¼çš„æ ¸å¿ƒåè¯ã€‚

äººåä¸€è‡´æ€§ä¸“é¡¹è§„åˆ™ï¼š
å·²ç¡®ç«‹çš„äººåæ˜ å°„å…³ç³»è§†ä¸º"å¼ºç»‘å®šè§„åˆ™"ï¼Œä¸å¯æ‹†åˆ†æˆ–æ··ç”¨ï¼š
ä¾‹å¦‚ï¼šì´í•´ë“  â†’ ææµ·ç¯ï¼ˆè§’è‰²å…¨åï¼‰ï¼Œí•´ë“  â†’ æµ·ç¯ï¼ˆåŒä¸€è§’è‰²çš„çœç•¥å/ç§°å‘¼ï¼‰
è‹¥åŸæ–‡ä¸­å‡ºç°ï¼š
å…¨åå½¢å¼ â†’ å¿…é¡»ä½¿ç”¨å¯¹åº”çš„å®Œæ•´ä¸­æ–‡å
çœç•¥/ç§°å‘¼å½¢å¼ â†’ å¿…é¡»ä½¿ç”¨ä¸ä¹‹åŒ¹é…çš„çœç•¥ä¸­æ–‡å
ç¦æ­¢ä»¥ä¸‹é”™è¯¯è¡Œä¸ºï¼š
ä¾‹å¦‚ï¼šå°† ì´í•´ë“  è¯‘ä¸ºã€Œæµ·ç¯ã€ï¼Œå°† í•´ë“  è¯‘ä¸ºã€Œææµ·ç¯ã€
åŒä¸€è§’è‰²çš„ä¸åŒåç§°å½¢å¼ï¼ˆå…¨å/çœç•¥å/æ˜µç§°ï¼‰è§†ä¸º"åŒä¸€äººåæœ¯è¯­ç»„"ï¼Œ
è¯¥æœ¯è¯­ç»„ä¸­çš„æ‰€æœ‰æ¡ç›® å¿…é¡»å…±äº«å®Œå…¨ä¸€è‡´çš„è§’è‰²å±æ€§ï¼ŒåŒ…æ‹¬ä½†ä¸é™äºï¼š
æ€§åˆ«ï¼ˆç”·æ€§/å¥³æ€§ï¼‰
è§’è‰²èº«ä»½
å™äº‹ç«‹åœº
æ€§åˆ«ä¸€è‡´æ€§å¼ºåˆ¶è§„åˆ™ï¼š
ä¸€æ—¦æŸè§’è‰²åœ¨ä»»ä¸€åç§°å½¢å¼ä¸­è¢«æ˜ç¡®åˆ¤å®šä¸ºç”·æ€§æˆ–å¥³æ€§è§’è‰²ï¼Œ
è¯¥æ€§åˆ«å±æ€§å¿…é¡»è‡ªåŠ¨ç»§æ‰¿è‡³è¯¥è§’è‰²çš„æ‰€æœ‰å…¶ä»–åç§°å½¢å¼ã€‚
ç¦æ­¢å°†åŒä¸€è§’è‰²çš„ä¸åŒåç§°å½¢å¼åˆ¤å®šä¸ºï¼š
"ä¸€ä¸ªæœ‰æ€§åˆ«ï¼Œä¸€ä¸ªæœªå®šä¹‰"
"ä¸€ä¸ªç”·æ€§ï¼Œä¸€ä¸ªæ€§åˆ«ä¸æ˜"
"ä¸€ä¸ªç”·æ€§ï¼Œä¸€ä¸ªå¥³æ€§"
åœ¨åŒä¸€å°è¯´ä¸­å¯¹åŒä¸€è§’è‰²ä½¿ç”¨å¤šä¸ªä¸æˆä½“ç³»çš„ä¸­æ–‡å
è‹¥æœ¯è¯­ä¸ºäººåï¼š
å¿…é¡»åˆ¤æ–­å…¶æ˜¯å¦ä¸ºå·²å‡ºç°è§’è‰²æˆ–å…¶å˜ä½“æŒ‡ä»£
è‹¥ä¸ºåŒä¸€è§’è‰²çš„ä¸åŒå†™æ³•ï¼Œåº”æ ‡è®°ä¸º"ä¸€è‡´æ€§æ­£ç¡®ï¼Œä¸ä¿®æ”¹"
ä¸å¾—å› "éå…¨å""çœ‹ä¼¼é€šç”¨"è€Œå»ºè®®åˆ é™¤

ç»„ç»‡ä¸€è‡´æ€§ä¸“é¡¹è§„åˆ™ï¼š
ç»„ç»‡ã€æœºæ„ã€å›¢ä½“ã€åŠ¿åŠ›ã€å…¬å¸ã€å­¦æ ¡ã€å¸®æ´¾ç­‰ï¼Œå‡è§†ä¸ºä¸“æœ‰åè¯ï¼Œå…¶ä¸€è‡´æ€§è§„åˆ™ç­‰åŒäºäººåã€‚
ä¸€æ—¦æŸç»„ç»‡çš„ä¸­è¯‘ååœ¨å°è¯´ä¸­è¢«ç¡®ç«‹ï¼Œå³è§†ä¸º"å¼ºç»‘å®šç»„ç»‡è¯‘å"ï¼Œåç»­å‡ºç°ä¸å¾—éšæ„æ”¹å†™ã€ç®€åŒ–æˆ–æ›¿æ¢åŒä¹‰è¡¨è¾¾ã€‚
éœ€ä¸»åŠ¨è¯†åˆ«ä»¥ä¸‹æƒ…å†µï¼Œå¹¶å¼ºåˆ¶ä¿æŒä¸€è‡´ï¼š
å…¨ç§° â†” ç®€ç§°
æ­£å¼åç§° â†” å†…éƒ¨ç§°å‘¼/ä¿—ç§°
åŸæ–‡ä¸­å› è¯­å¢ƒçœç•¥éƒ¨åˆ†è¯ç´ çš„ç»„ç»‡æŒ‡ä»£å½¢å¼
ç¦æ­¢ä»¥ä¸‹è¡Œä¸ºï¼š
åŒä¸€ç»„ç»‡åœ¨ä¸åŒç« èŠ‚ä½¿ç”¨ä¸åŒä¸­æ–‡è¯‘å
å°†å·²ç¡®ç«‹è¯‘åçš„ç»„ç»‡è¯¯åˆ¤ä¸º"é€šç”¨åè¯"å¹¶å»ºè®®åˆ é™¤
å› å­—é¢ç›´è¯‘æˆ–é£æ ¼åå¥½æ“…è‡ªæ›´æ¢å·²ç¨³å®šçš„ç»„ç»‡è¯‘å
è‹¥æœ¯è¯­ä¸ºç»„ç»‡åï¼š
å¿…é¡»åˆ¤æ–­å…¶æ˜¯å¦ä¸ºå·²å‡ºç°ç»„ç»‡æˆ–å…¶å˜ä½“æŒ‡ä»£
è‹¥ä¸ºåŒä¸€ç»„ç»‡çš„ä¸åŒå†™æ³•ï¼Œåº”åˆ¤å®šä¸º"ä¸€è‡´æ€§æ­£ç¡®ï¼Œä¸ä¿®æ”¹"
ä»…åœ¨æ˜æ˜¾ç¿»è¯‘é”™è¯¯æˆ–è¿èƒŒå°è¯´è®¾å®šæ—¶ï¼Œæ‰å…è®¸æå‡ºä¿®æ­£å»ºè®®

ä»»åŠ¡ï¼šæ‰¹é‡æœ¯è¯­å®¡æŸ¥
è¯·æ ¹æ®ã€Œå°è¯´èƒŒæ™¯è®¾å®šã€ä¸æ¯ä¸ªæœ¯è¯­å„è‡ªçš„ã€Œæœ¯è¯­æ‰€åœ¨åŸæ–‡å‚è€ƒã€ï¼Œé€æ¡ã€ç‹¬ç«‹åˆ¤æ–­ä¸‹åˆ—æœ¯è¯­æ˜¯å¦å­˜åœ¨ç¿»è¯‘é—®é¢˜ã€‚

å®¡æŸ¥æ ‡å‡†ï¼š
æ˜¯å¦ä¸ºå¤šä¹‰è¯ã€ä¸”æ— æ³•ç¨³å®šæŒ‡å‘å…·ä½“å«ä¹‰ï¼Ÿï¼ˆå»ºè®®åˆ é™¤ï¼‰
ç¿»è¯‘æ˜¯å¦å‡†ç¡®ï¼Œæ˜¯å¦ç¬¦åˆå°è¯´è¯­å¢ƒï¼Ÿ
æ˜¯å¦ä¸ºæ— æ­§ä¹‰çš„é€šç”¨æ—¥å¸¸è¯ï¼Ÿï¼ˆå»ºè®®åˆ é™¤ï¼‰
æ˜¯å¦ä¸ºå½¢å®¹è¯ã€åŠ¨è¯æˆ–çº¯æè¿°æ€§çŸ­è¯­ï¼Ÿï¼ˆå»ºè®®åˆ é™¤ï¼‰
è‹¥ä¸ºè§’è‰²æœ¯è¯­ï¼š
æ˜¯å¦ä¸ºäººåæˆ–å…¶æŒ‡ä»£å½¢å¼ï¼Ÿ
æ˜¯å¦ä¸æ—¢å®šäººåæ˜ å°„ä¿æŒä¸€è‡´ï¼Ÿ
æ€§åˆ«ã€ç§°å‘¼å±‚çº§æ˜¯å¦æ­£ç¡®ï¼Ÿ
è‹¥ä¸ºç»„ç»‡æœ¯è¯­ï¼š
æ˜¯å¦ä¸ºå·²ç¡®ç«‹ç»„ç»‡æˆ–å…¶å˜ä½“æŒ‡ä»£ï¼Ÿ
æ˜¯å¦ä¸æ—¢å®šç»„ç»‡è¯‘åä¿æŒä¸€è‡´ï¼Ÿ
è‹¥éè§’è‰²æˆ–æ ¸å¿ƒè®¾å®šç›¸å…³æœ¯è¯­ï¼Œæ˜¯å¦åº”åˆ é™¤ï¼Ÿ"""

        # Fixed part that handles formatting and examples
        fixed_suffix = f"""
å°è¯´èƒŒæ™¯è®¾å®š:
{novel_background}

è¯·ä¸¥æ ¼æŒ‰ç…§æˆ‘ç»™å‡ºçš„ JSON æ ¼å¼è¿”å›ä¸€ä¸ªåŒ…å«æ‰€æœ‰æœ¯è¯­å®¡æŸ¥ç»“æœçš„ JSON åˆ—è¡¨ã€‚åˆ—è¡¨çš„é¡ºåºå¿…é¡»ä¸è¾“å…¥åˆ—è¡¨çš„é¡ºåºå®Œå…¨ä¸€è‡´ã€‚

ä¸‹é¢æ˜¯ä¸€ä¸ªå¤„ç†èŒƒä¾‹ï¼š
---
[èŒƒä¾‹è¾“å…¥]
[
  {{ "korean_term": "ì¹¨ëŒ€ ì‹œíŠ¸", "chinese_translation": "åºŠå•", "is_character": false, "context": "ê·¸ëŠ” ì¹¨ëŒ€ ì‹œíŠ¸ë¥¼ ê°ˆì•˜ë‹¤. (ä»–æ¢äº†åºŠå•ã€‚)" }},
  {{ "korean_term": "í˜„ì¬ì›…", "chinese_translation": "ç„åœ¨é›„", "is_character": true, "context": "í˜„ì¬ì›…ì€ ë§í–ˆë‹¤. (ç„åœ¨é›„è¯´é“ã€‚)" }}
]

[èŒƒä¾‹è¾“å‡º]
[
  {{
    "korean_term": "ì¹¨ëŒ€ ì‹œíŠ¸",
    "original_translation": "åºŠå•",
    "recommended_translation": "åºŠå•",
    "should_delete": true,
    "deletion_reason": "é€šç”¨è¯",
    "judgment_emoji": "ğŸ—‘ï¸",
    "justification": "è¯¥æœ¯è¯­ä¸ºé€šç”¨è¯ï¼ˆæ—¥å¸¸è¯æ±‡ï¼‰ï¼Œæ— ç‰¹æ®Šå«ä¹‰ï¼Œå»ºè®®åœ¨æœ€ç»ˆæœ¯è¯­è¡¨ä¸­åˆ é™¤ã€‚"
  }},
  {{
    "korean_term": "í˜„ì¬ì›…",
    "original_translation": "ç„åœ¨é›„",
    "recommended_translation": "ç„åœ¨é›„",
    "should_delete": false,
    "deletion_reason": null,
    "judgment_emoji": "âœ…",
    "justification": "è§’è‰²åç¿»è¯‘å‡†ç¡®ï¼Œä¸èƒŒæ™¯ä¸€è‡´ã€‚"
  }}
]
---

ç°åœ¨ï¼Œè¯·å¤„ç†ä»¥ä¸‹æœ¯è¯­åˆ—è¡¨ï¼š
{json.dumps(batch_list, ensure_ascii=False, indent=2)}

è¾“å‡ºæ ¼å¼ (Output Format):
[
  {{
    "korean_term": "[æœ¯è¯­åŸæ–‡]",
    "original_translation": "[åŸå§‹è¯‘æ–‡]",
    "recommended_translation": "[ä½ çš„é¦–é€‰å»ºè®®]",
    "should_delete": "[true/false]",
    "deletion_reason": "[é€šç”¨è¯/åŠ¨è¯/å½¢å®¹è¯/æè¿°æ€§çŸ­è¯­/éè§’è‰²/å…¶ä»–/null]",
    "judgment_emoji": "[âœ…/âš ï¸/âŒ/ğŸ—‘ï¸]",
    "justification": "[ç®€æ´ã€ç²¾ç¡®çš„æ ¸å¿ƒç†ç”±]"
  }}
]
"""
        return user_prompt + "\n" + fixed_suffix

    def _parse_json_response(self, response_text):
        if not response_text: return None
        clean_text = re.sub(r'```json\s*|\s*```', '', response_text).strip()
        try:
            return json.loads(clean_text)
        except json.JSONDecodeError:
            # Simple fallback for list extraction
            match = re.search(r'\[.*\]', clean_text, re.DOTALL)
            if match:
                try:
                    return json.loads(match.group(0))
                except:
                    pass
            return None
