import pandas as pd
import json
import re
import os
import concurrent.futures
from backend.core.ai_service import AIService
from backend.config_manager import load_config

class GlossaryProcessor:
    def __init__(self, ai_service: AIService):
        self.ai_service = ai_service
        self.config = load_config()

    def load_data(self, glossary_path, reference_path):
        glossary_df = pd.read_excel(glossary_path, engine='openpyxl')
        original_cols = glossary_df.columns.tolist()
        rename_map = {original_cols[0]: 'src', original_cols[1]: 'dst'}
        glossary_df = glossary_df.rename(columns=rename_map)
        
        # Ensure src and dst are strings, but leave other columns (like count) as is
        glossary_df['src'] = glossary_df['src'].fillna('').astype(str)
        glossary_df['dst'] = glossary_df['dst'].fillna('').astype(str)

        with open(reference_path, 'r', encoding='utf-8') as f:
            content = f.read().replace('\r\n', '\n').replace('\r', '\n')
        
        blocks = content.split('åŸæ–‡ï¼š')[1:]
        reference_dict = {}
        for block in blocks:
            match = re.search(r'^(?P<korean_term>.*?)\n.*?(?P<context>.*)', block, re.DOTALL)
            if match:
                korean_term = match.group('korean_term').strip()
                context = match.group('context').strip().replace("â€»", "")
                reference_dict[korean_term] = context
        
        return glossary_df, reference_dict, original_cols

    def process_batch(self, batch_df, novel_background, reference_dict, log_callback=None):
        batch_list = []
        character_keywords = ['è§’è‰²', 'ç¥ç¥‡/ä¼ è¯´äººç‰©', 'ç”·æ€§è§’è‰²', 'å¥³æ€§è§’è‰²']
        for _, row in batch_df.iterrows():
            korean_term = row['src'].strip()
            batch_list.append({
                "korean_term": korean_term,
                "chinese_translation": row['dst'].strip(),
                "is_character": any(keyword in row.get('info', '') for keyword in character_keywords),
                "context": reference_dict.get(korean_term, f"æœªåœ¨å‚è€ƒæ–‡ä»¶ä¸­æ‰¾åˆ°æœ¯è¯­ '{korean_term}' çš„ä¸Šä¸‹æ–‡ã€‚")
            })
        
        prompt = self._get_batch_prompt(novel_background, batch_list)
        response = self.ai_service.call_api(prompt, log_callback=log_callback)
        return self._parse_json_response(response)

    def _get_batch_prompt(self, novel_background, batch_list):
        user_prompt = self.config.get("prompts", {}).get("batch_review", "")
        if not user_prompt:
             # Fallback default if config is empty
             user_prompt = """è§’è‰²ï¼šä¸“ä¸šå°è¯´ç¿»è¯‘å®¶ (V3 - æ‰¹å¤„ç†æ¨¡å¼)

èº«ä»½ä¸ä½¿å‘½:
ä½ æ˜¯ä¸€ä½é¡¶çº§çš„éŸ©ä¸­ç¿»è¯‘å¤å®¡ä¸“å®¶ã€‚ä½ çš„ä»»åŠ¡æ˜¯æ¥æ”¶ä¸€æ‰¹æœ¯è¯­ï¼Œå¹¶å¯¹å…¶ä¸­çš„æ¯ä¸€æ¡è¿›è¡Œç‹¬ç«‹çš„ã€ç²¾ç¡®çš„å®¡æŸ¥ã€‚

æ ¸å¿ƒè¡Œä¸ºå‡†åˆ™:
- ç»å¯¹å¿ äºâ€œå°è¯´èƒŒæ™¯è®¾å®šâ€å’Œâ€œæœ¯è¯­æ‰€åœ¨åŸæ–‡å‚è€ƒâ€ï¼Œè¿™æ˜¯ä½ åˆ¤æ–­çš„æœ€é«˜ä¾æ®ã€‚
- å¯¹äºä¸“æœ‰åè¯ï¼ˆäººåã€åœ°åã€ç»„ç»‡ç­‰ï¼‰ï¼Œä½ çš„é¦–è¦ä»»åŠ¡æ˜¯ç¡®ä¿å…¶â€œä¸€è‡´æ€§â€ï¼Œåœ¨æ²¡æœ‰æ˜æ˜¾é”™è¯¯çš„æƒ…å†µä¸‹ä¸è½»æ˜“ä¿®æ”¹ã€‚
- å¯¹äºæ™®é€šè¯æ±‡ï¼Œä½ çš„ä»»åŠ¡æ˜¯â€œç²¾ç®€â€ï¼Œå¤§èƒ†åœ°åˆ é™¤ä¸å¿…è¦çš„é€šç”¨è¯ã€åŠ¨è¯å’Œæè¿°æ€§çŸ­è¯­ï¼Œåªä¿ç•™æ ¸å¿ƒåè¯ã€‚


ä»»åŠ¡ï¼šæ‰¹é‡æœ¯è¯­å®¡æŸ¥
è¯·æ ¹æ®â€œå°è¯´èƒŒæ™¯è®¾å®šâ€å’Œæ¯ä¸ªæœ¯è¯­å„è‡ªçš„â€œæœ¯è¯­æ‰€åœ¨åŸæ–‡å‚è€ƒâ€ï¼Œç‹¬ç«‹åˆ¤æ–­åˆ—è¡¨ä¸­çš„æ¯ä¸€ä¸ªæœ¯è¯­æ˜¯å¦æœ‰ç¿»è¯‘é—®é¢˜ã€‚
å®¡æŸ¥æ ‡å‡†å¦‚ä¸‹ï¼š
1. æ˜¯å¦ä¸ºå¤šä¹‰è¯ï¼Ÿï¼ˆå»ºè®®åˆ é™¤ï¼‰
2. ç¿»è¯‘æ˜¯å¦å‡†ç¡®ï¼Ÿ
3. æ˜¯å¦ä¸ºé€šç”¨è¯ï¼ˆå³æ²¡æœ‰æ­§ä¹‰çš„æ—¥å¸¸è¯æ±‡ï¼Œå¦‚â€œåºŠå•â€ã€â€œæ°´å£¶â€ï¼‰ï¼Ÿï¼ˆå»ºè®®åˆ é™¤ï¼‰
4. æ˜¯å¦ä¸ºå½¢å®¹è¯ã€åŠ¨è¯æˆ–æè¿°æ€§çŸ­è¯­ï¼Ÿï¼ˆå»ºè®®åˆ é™¤ï¼‰
5. å¦‚æœæ˜¯è§’è‰²æœ¯è¯­ï¼Œäººåã€æ€§åˆ«ã€ä¸€è‡´æ€§æ˜¯å¦æ­£ç¡®ï¼Ÿå¦‚æœä¸æ˜¯è§’è‰²ï¼Œæ˜¯å¦åº”åˆ é™¤ï¼Ÿ"""

        # Fixed part that handles formatting and examples
        fixed_suffix = f"""
å°è¯´èƒŒæ™¯è®¾å®š:
{novel_background}

è¯·ä¸¥æ ¼æŒ‰ç…§æˆ‘ç»™å‡ºçš„ JSON æ ¼å¼è¿”å›ä¸€ä¸ªåŒ…å«æ‰€æœ‰æœ¯è¯­å®¡æŸ¥ç»“æœçš„ JSON åˆ—è¡¨ã€‚åˆ—è¡¨çš„é¡ºåºå¿…é¡»ä¸è¾“å…¥åˆ—è¡¨çš„é¡ºåºå®Œå…¨ä¸€è‡´ã€‚

ä¸‹é¢æ˜¯ä¸€ä¸ªå¤„ç†èŒƒä¾‹ï¼š
---
[èŒƒä¾‹è¾“å…¥]
[
  {{ "korean_term": "ì¹¨ëŒ€ ì‹œíŠ¸", "chinese_translation": "åºŠå•", "is_character": false, "context": "ê·¸ëŠ” ì¹¨ëŒ€ ì‹œíŠ¸ë¥¼ ê°ˆì•˜ë‹¤. (ä»–æ¢äº†åºŠå•ã€‚)" }},
  {{ "korean_term": "í˜„ì¬ì›…", "chinese_translation": "ç„åœ¨é›„", "is_character": true, "context": "í˜„ì¬ì›…ì€ ë§í–ˆë‹¤. (ç„åœ¨é›„è¯´é“ã€‚)" }}
]

[èŒƒä¾‹è¾“å‡º]
[
  {{
    "korean_term": "ì¹¨ëŒ€ ì‹œíŠ¸",
    "original_translation": "åºŠå•",
    "recommended_translation": "åºŠå•",
    "should_delete": true,
    "deletion_reason": "é€šç”¨è¯",
    "judgment_emoji": "ğŸ—‘ï¸",
    "justification": "è¯¥æœ¯è¯­ä¸ºé€šç”¨è¯ï¼ˆæ—¥å¸¸è¯æ±‡ï¼‰ï¼Œæ— ç‰¹æ®Šå«ä¹‰ï¼Œå»ºè®®åœ¨æœ€ç»ˆæœ¯è¯­è¡¨ä¸­åˆ é™¤ã€‚"
  }},
  {{
    "korean_term": "í˜„ì¬ì›…",
    "original_translation": "ç„åœ¨é›„",
    "recommended_translation": "ç„åœ¨é›„",
    "should_delete": false,
    "deletion_reason": null,
    "judgment_emoji": "âœ…",
    "justification": "è§’è‰²åç¿»è¯‘å‡†ç¡®ï¼Œä¸èƒŒæ™¯ä¸€è‡´ã€‚"
  }}
]
---

ç°åœ¨ï¼Œè¯·å¤„ç†ä»¥ä¸‹æœ¯è¯­åˆ—è¡¨ï¼š
{json.dumps(batch_list, ensure_ascii=False, indent=2)}

è¾“å‡ºæ ¼å¼ (Output Format):
[
  {{
    "korean_term": "[æœ¯è¯­åŸæ–‡]",
    "original_translation": "[åŸå§‹è¯‘æ–‡]",
    "recommended_translation": "[ä½ çš„é¦–é€‰å»ºè®®]",
    "should_delete": "[true/false]",
    "deletion_reason": "[é€šç”¨è¯/åŠ¨è¯/å½¢å®¹è¯/æè¿°æ€§çŸ­è¯­/éè§’è‰²/å…¶ä»–/null]",
    "judgment_emoji": "[âœ…/âš ï¸/âŒ/ğŸ—‘ï¸]",
    "justification": "[ç®€æ´ã€ç²¾ç¡®çš„æ ¸å¿ƒç†ç”±]"
  }}
]
"""
        return user_prompt + "\n" + fixed_suffix

    def _parse_json_response(self, response_text):
        if not response_text: return None
        clean_text = re.sub(r'```json\s*|\s*```', '', response_text).strip()
        try:
            return json.loads(clean_text)
        except json.JSONDecodeError:
            # Simple fallback for list extraction
            match = re.search(r'\[.*\]', clean_text, re.DOTALL)
            if match:
                try:
                    return json.loads(match.group(0))
                except:
                    pass
            return None
